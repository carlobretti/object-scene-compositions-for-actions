{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /Users/carlo/opt/anaconda3/lib/python3.8/site-packages (0.9.2)\r\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/carlo/opt/anaconda3/lib/python3.8/site-packages (from fasttext) (50.3.1.post20201107)\r\n",
      "Requirement already satisfied: pybind11>=2.2 in /Users/carlo/opt/anaconda3/lib/python3.8/site-packages (from fasttext) (2.6.2)\r\n",
      "Requirement already satisfied: numpy in /Users/carlo/opt/anaconda3/lib/python3.8/site-packages (from fasttext) (1.19.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "import fasttext\n",
    "import numpy as np\n",
    "from   scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = {\"en\":\"English\", \"af\":\"Afrikaans\", \"nl\":\"Dutch\", \"fr\":\"French\", \"pt\":\"Portuguese\"}\n",
    "\n",
    "# download pretrained ft models for languages of choice \n",
    "for lang_short in langs.keys():\n",
    "    fasttext.util.download_model(lang_short, if_exists='ignore')  # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# generate and store embeddings for all labels for the three datasets\n",
    "\n",
    "for dataset in [\"imagenet\", \"places-365\", \"ucf-101\"]:\n",
    "    ds_folder = f\"data/{dataset}/\"\n",
    "    ds_wd_folder = ds_folder+\"words/\"\n",
    "    ds_ft_folder = ds_folder+\"fasttext/\"\n",
    "\n",
    "\n",
    "    !mkdir -p \"$ds_ft_folder\"\n",
    "    \n",
    "    dataset = \"imagenet12988\" if dataset == \"imagenet\" else dataset.replace(\"-\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "    for lang_short, lang in langs.items():\n",
    "        with open(ds_wd_folder+f\"{dataset}-words-{lang}.txt\", 'r') as f:\n",
    "            labels = f.readlines()\n",
    "        labels = [label.strip() for label in labels]    \n",
    "        ft = fasttext.load_model(f'cc.{lang_short}.300.bin')\n",
    "\n",
    "        embeddings = np.array([ft.get_sentence_vector(label) for label in labels]) #should .get_sentence_vector be used here or should we average out all the word embeddings?\n",
    "        np.save(ds_ft_folder+f\"fasttext-{dataset}-{lang}.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Pair-wise similarity between (action and scene), (action and object), and (scene and object) word embeddings.\n",
    "#\n",
    "def wtv_mapping(wtv1, wtv2):\n",
    "    wtvmap = np.zeros((wtv1.shape[0], wtv2.shape[0]), dtype=np.float32)\n",
    "    for i in range(wtv1.shape[0]):\n",
    "        for j in range(wtv2.shape[0]):\n",
    "            wtvmap[i,j] = 1 - cosine(wtv1[i], wtv2[j])\n",
    "    return wtvmap\n",
    "\n",
    "\n",
    "for ds1, ds2 in [(\"imagenet\", \"places-365\"),(\"ucf-101\", \"places-365\"), (\"ucf-101\", \"imagenet\")]:\n",
    "    ds1_ft_folder = f\"data/{ds1}/fasttext/\"\n",
    "    ds2_ft_folder = f\"data/{ds2}/fasttext/\"\n",
    "    \n",
    "    ds1 = \"imagenet12988\" if ds1 == \"imagenet\" else ds1.replace(\"-\", \"\")\n",
    "    ds2 = \"imagenet12988\" if ds2 == \"imagenet\" else ds2.replace(\"-\", \"\")\n",
    "    \n",
    "    for lang_short, lang in langs.items():\n",
    "        ds1_emb = np.load(ds1_ft_folder+f\"fasttext-{ds1}-{lang}.npy\")\n",
    "        ds2_emb = np.load(ds2_ft_folder+f\"fasttext-{ds2}-{lang}.npy\")\n",
    "        \n",
    "        emb2emb = wtv_mapping(ds1_emb, ds2_emb)\n",
    "        \n",
    "        corr = {\"imagenet12988\":\"o\", \"places365\":\"s\", \"ucf101\":\"a\"}\n",
    "        \n",
    "        np.save(ds1_ft_folder+f\"{corr[ds1]}2{corr[ds2]}_ft_{ds2}_{lang}.npy\", emb2emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
