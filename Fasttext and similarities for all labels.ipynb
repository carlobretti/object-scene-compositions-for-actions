{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /Users/carlo/opt/anaconda3/lib/python3.8/site-packages (0.9.2)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/carlo/opt/anaconda3/lib/python3.8/site-packages (from fasttext) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pybind11>=2.2 in /Users/carlo/opt/anaconda3/lib/python3.8/site-packages (from fasttext) (2.6.2)\n",
      "Requirement already satisfied: numpy in /Users/carlo/opt/anaconda3/lib/python3.8/site-packages (from fasttext) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "import fasttext\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import os\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import sparse\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = {\"en\":\"English\", \"af\":\"Afrikaans\", \"nl\":\"Dutch\", \"fr\":\"French\", \"pt\":\"Portuguese\"}\n",
    "\n",
    "# download pretrained ft models for languages of choice \n",
    "for lang_short in langs.keys():\n",
    "    fasttext.util.download_model(lang_short, if_exists='ignore')  # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "def custom_get_sentence_vector(ft, text):\n",
    "    # custom get sentence vector to avoid adding the EOS token like in ft.get_sentence_vector\n",
    "    vecs = []\n",
    "    norms = []\n",
    "    for token in text.split():\n",
    "        vec = ft.get_word_vector(token)\n",
    "        vecs.append(vec)\n",
    "        norms.append(LA.norm(vec))\n",
    "    avged = np.mean([vec/norm if norm>0 else vec for vec, norm in zip(vecs,norms)], axis = 0)\n",
    "    return avged\n",
    "\n",
    "# generate and store embeddings for all labels for the three datasets\n",
    "\n",
    "for dataset in [\"imagenet\", \"places-365\", \"ucf-101\"]:\n",
    "    ds_folder = f\"data/{dataset}/\"\n",
    "    ds_wd_folder = ds_folder+\"words/\"\n",
    "    ds_ft_folder = ds_folder+\"fasttext/\"\n",
    "\n",
    "\n",
    "    os.system(f\"mkdir -p {ds_ft_folder}\")\n",
    "    \n",
    "    dataset = \"imagenet12988\" if dataset == \"imagenet\" else dataset.replace(\"-\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "    for lang_short, lang in langs.items():\n",
    "        with open(ds_wd_folder+f\"{dataset}-words-{lang}.txt\", 'r') as f:\n",
    "            labels = f.readlines()\n",
    "        labels = [label.strip().replace(\"_\", \" \") for label in labels]    \n",
    "        ft = fasttext.load_model(f'cc.{lang_short}.300.bin')\n",
    "\n",
    "#         embeddings = np.array([ft.get_sentence_vector(label) for label in labels]) #should .get_sentence_vector be used here or should we average out all the word embeddings?\n",
    "        embeddings = np.array([custom_get_sentence_vector(ft, label) for label in labels])\n",
    "        np.save(ds_ft_folder+f\"fasttext-{dataset}-{lang}.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and store embeddings for object-scene label pairs for the three datasets\n",
    "\n",
    "for lang_short, lang in langs.items():\n",
    "#     with open(f\"data/imagenet/words/imagenet12988-words-{lang}.txt\", 'r') as f:\n",
    "#         objlabels = f.readlines()\n",
    "#     objlabels = [label.strip().replace(\"_\", \" \") for label in objlabels]\n",
    "#     with open(f\"data/places-365/words/places365-words-{lang}.txt\", 'r') as f:\n",
    "#         scelabels = f.readlines()\n",
    "#     scelabels = [label.strip().replace(\"_\", \" \") for label in scelabels]\n",
    "# #     print([objlabel+\" \"+scelabel for objlabel in objlabels for scelabel in scelabels][:10])\n",
    "#     ft = fasttext.load_model(f'cc.{lang_short}.300.bin')\n",
    "    \n",
    "#     embeddings = np.array([ft.get_sentence_vector(objlabel+\" \"+scelabel) for objlabel in objlabels for scelabel in scelabels]) #should .get_sentence_vector be used here or should we average out all the word embeddings?\n",
    "    \n",
    "    imagenet_vecs = np.load(f\"data/imagenet/fasttext/fasttext-imagenet12988-{lang}.npy\")\n",
    "    places_vecs = np.load(f\"data/places-365/fasttext/fasttext-places365-{lang}.npy\")\n",
    "    \n",
    "    \n",
    "    ds_ft_folder = \"data/imagenet_places/fasttext/\"\n",
    "    os.system(f\"mkdir -p {ds_ft_folder}\")\n",
    "    \n",
    "    # averaging the embedding for object and for scene without dividing by norm\n",
    "    embeddings = np.array([np.mean([places_vec, imagenet_vec], axis = 0) for imagenet_vec in imagenet_vecs for places_vec in places_vecs])\n",
    "    # also dividing by norm?\n",
    "#     embeddings = np.array([np.mean([places_vec/LA.norm(places_vec), imagenet_vec/LA.norm(imagenet_vec)], axis = 0) for imagenet_vec in imagenet_vecs for places_vec in places_vecs])\n",
    "    # weighted average of object and scene vectors, which does not work really well\n",
    "#     lam = 0.8 # this way objects are more important than scenes\n",
    "#     embeddings = np.array([ lam*places_vec+(1-lam)*imagenet_vec for imagenet_vec in imagenet_vecs for places_vec in places_vecs])\n",
    "    \n",
    "    np.save(ds_ft_folder+f\"fasttext-imagenet12988places365pairs-{lang}.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Pair-wise similarity between (action and scene), (action and object), (object and object), (scene and scene), (scene and object) word embeddings.\n",
    "#\n",
    "def wtv_mapping(wtv1, wtv2):\n",
    "    wtvmap = cdist(wtv1, wtv2, metric = \"cosine\")\n",
    "    return 1 - wtvmap\n",
    "\n",
    "\n",
    "for ds1, ds2 in [(\"imagenet\", \"places-365\"), (\"ucf-101\", \"places-365\"), (\"ucf-101\", \"imagenet\"), (\"imagenet\", \"imagenet\"), (\"places-365\", \"places-365\")]:\n",
    "    ds1_ft_folder = f\"data/{ds1}/fasttext/\"\n",
    "    ds2_ft_folder = f\"data/{ds2}/fasttext/\"\n",
    "    \n",
    "    ds1 = \"imagenet12988\" if ds1 == \"imagenet\" else ds1.replace(\"-\", \"\")\n",
    "    ds2 = \"imagenet12988\" if ds2 == \"imagenet\" else ds2.replace(\"-\", \"\")\n",
    "    \n",
    "    for lang_short, lang in langs.items():\n",
    "        ds1_emb = np.load(ds1_ft_folder+f\"fasttext-{ds1}-{lang}.npy\")\n",
    "        ds2_emb = np.load(ds2_ft_folder+f\"fasttext-{ds2}-{lang}.npy\")\n",
    "        \n",
    "        emb2emb = wtv_mapping(ds1_emb, ds2_emb)\n",
    "        \n",
    "        corr = {\"imagenet12988\":\"o\", \"places365\":\"s\", \"ucf101\":\"a\"}\n",
    "        \n",
    "        np.save(ds1_ft_folder+f\"{corr[ds1]}2{corr[ds2]}_ft_{ds2}_{lang}.npy\", emb2emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing pairwise similarity for object-scene pairs and actions\n",
    "\n",
    "for lang_short, lang in langs.items():\n",
    "    ds1_emb = np.load(f\"data/ucf-101/fasttext/fasttext-ucf101-{lang}.npy\")\n",
    "    ds2_emb = np.load(f\"data/imagenet_places/fasttext/fasttext-imagenet12988places365pairs-{lang}.npy\")\n",
    "\n",
    "    \n",
    "    emb2emb = wtv_mapping(ds2_emb, ds1_emb)\n",
    "    np.save(f\"data/ucf-101/fasttext/a2ospairs_ft_imagenet12988places365pairs_{lang}.npy\", emb2emb.T)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# # compute np.mean(ospairs2ospairs,axis = 0) rather than ospairs2ospairs, since we can't compute that\n",
    "# # yea no way we can compute this\n",
    "#     ospairs2ospairsmeans = np.array([])\n",
    "#     stepsize = 100\n",
    "#     for i in tqdm(range(0, ds2_emb.shape[0], stepsize)):\n",
    "#         ospairs2ospairsmeans = np.append(ospairs2ospairsmeans, np.mean(wtv_mapping(ds2_emb, ds2_emb[i:i+stepsize]), axis = 0))\n",
    "#     np.save(f\"data/imagenet_places/fasttext/ospairs2ospairsmean_imagenet12988places365pairs_{lang}.npy\",ospairs2ospairsmeans[..., np.newaxis])\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # # This is part of the failed attempt at using sparse matrices to store ospairs2ospairs\n",
    "#     action_nr = ds1_emb.shape[0]\n",
    "#     pairs_nr = ds2_emb.shape[0]\n",
    "#     ospairs2ospairs = sparse.coo_matrix((pairs_nr,pairs_nr))\n",
    "\n",
    "#     ds_os2os_folder = f\"data/imagenet_places/fasttext/ospairs2ospairs_{action_nr}/{lang}/\"\n",
    "#     for i in range(1,action_nr+1):\n",
    "#         os.system(f\"mkdir -p {ds_os2os_folder}action{i}\")\n",
    "#         sparse.save_npz(f\"{ds_os2os_folder}/action{i}/ospairs2ospairs_imagenet12988places365pairs.npz\", ospairs2ospairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
